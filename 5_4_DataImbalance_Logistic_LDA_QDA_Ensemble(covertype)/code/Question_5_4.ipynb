{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Data/covtype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#581,012\n",
    "df_conv=pd.read_csv('./Data/covertype_name.csv')\n",
    "#1   3   6  12  14  24  27  28  34  44 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Elevation  Slope  Horizontal_Distance_To_Roadways  Wilderness_Area2  \\\n",
       "0            2596      3                              510                 0   \n",
       "1            2590      2                              390                 0   \n",
       "2            2804      9                             3180                 0   \n",
       "3            2785     18                             3090                 0   \n",
       "4            2595      2                              391                 0   \n",
       "...           ...    ...                              ...               ...   \n",
       "581007       2396     20                              108                 0   \n",
       "581008       2391     19                               95                 0   \n",
       "581009       2386     17                               90                 0   \n",
       "581010       2384     15                               90                 0   \n",
       "581011       2383     13                               67                 0   \n",
       "\n",
       "        Wilderness_Area4  Soil_Type10  Soil_Type13  Soil_Type14  Soil_Type20  \\\n",
       "0                      0            0            0            0            0   \n",
       "1                      0            0            0            0            0   \n",
       "2                      0            0            0            0            0   \n",
       "3                      0            0            0            0            0   \n",
       "4                      0            0            0            0            0   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "581007                 0            0            0            0            0   \n",
       "581008                 0            0            0            0            0   \n",
       "581009                 0            0            0            0            0   \n",
       "581010                 0            0            0            0            0   \n",
       "581011                 0            0            0            0            0   \n",
       "\n",
       "        Soil_Type30  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 0  \n",
       "...             ...  \n",
       "581007            0  \n",
       "581008            0  \n",
       "581009            0  \n",
       "581010            0  \n",
       "581011            0  \n",
       "\n",
       "[581012 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Elevation</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Wilderness_Area2</th>\n      <th>Wilderness_Area4</th>\n      <th>Soil_Type10</th>\n      <th>Soil_Type13</th>\n      <th>Soil_Type14</th>\n      <th>Soil_Type20</th>\n      <th>Soil_Type30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2596</td>\n      <td>3</td>\n      <td>510</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2590</td>\n      <td>2</td>\n      <td>390</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2804</td>\n      <td>9</td>\n      <td>3180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2785</td>\n      <td>18</td>\n      <td>3090</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2595</td>\n      <td>2</td>\n      <td>391</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>581007</th>\n      <td>2396</td>\n      <td>20</td>\n      <td>108</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>581008</th>\n      <td>2391</td>\n      <td>19</td>\n      <td>95</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>581009</th>\n      <td>2386</td>\n      <td>17</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>581010</th>\n      <td>2384</td>\n      <td>15</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>581011</th>\n      <td>2383</td>\n      <td>13</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>581012 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.iloc[:,[0,   2,   5,  11,  13,  23,  26,  27,  33 , 43 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=df_conv['V55']\n",
    "x=df_conv.drop('V55',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          V1   V2  V3    V4   V5    V6   V7   V8   V9   V10  ...  V45  V46  \\\n",
       "266280  2290  333  15   300   66   953  185  220  173   212  ...    0    0   \n",
       "306815  3244  109  19   134   18  1695  248  216   88  2914  ...    0    0   \n",
       "382286  3087   55   6  1328  202  3132  224  227  139  1224  ...    0    1   \n",
       "574300  2546  100  25    85   28  1897  252  196   57   553  ...    0    0   \n",
       "267484  2879  276  16   300   -4  1396  175  242  206  1518  ...    0    1   \n",
       "...      ...  ...  ..   ...  ...   ...  ...  ...  ...   ...  ...  ...  ...   \n",
       "397396  2977  113  16   912  182  2671  246  221   98  1598  ...    0    0   \n",
       "49723   2688  335  15    67   18  1290  184  218  173  3226  ...    0    0   \n",
       "156845  2996   14   9   242   54  3878  212  222  147  2592  ...    0    0   \n",
       "256753  2023  288  34    85   24   313  108  214  235   576  ...    0    0   \n",
       "538388  3208  287  16   150    4  4129  173  237  204  1800  ...    0    0   \n",
       "\n",
       "        V47  V48  V49  V50  V51  V52  V53  V54  \n",
       "266280    0    0    0    0    0    0    0    0  \n",
       "306815    0    0    0    0    0    0    1    0  \n",
       "382286    0    0    0    0    0    0    0    0  \n",
       "574300    0    0    0    0    0    0    0    0  \n",
       "267484    0    0    0    0    0    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "397396    0    0    0    0    0    0    0    0  \n",
       "49723     0    0    0    0    0    0    0    0  \n",
       "156845    0    0    0    0    0    0    0    0  \n",
       "256753    0    0    0    0    0    0    0    0  \n",
       "538388    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[389278 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V45</th>\n      <th>V46</th>\n      <th>V47</th>\n      <th>V48</th>\n      <th>V49</th>\n      <th>V50</th>\n      <th>V51</th>\n      <th>V52</th>\n      <th>V53</th>\n      <th>V54</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>266280</th>\n      <td>2290</td>\n      <td>333</td>\n      <td>15</td>\n      <td>300</td>\n      <td>66</td>\n      <td>953</td>\n      <td>185</td>\n      <td>220</td>\n      <td>173</td>\n      <td>212</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>306815</th>\n      <td>3244</td>\n      <td>109</td>\n      <td>19</td>\n      <td>134</td>\n      <td>18</td>\n      <td>1695</td>\n      <td>248</td>\n      <td>216</td>\n      <td>88</td>\n      <td>2914</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>382286</th>\n      <td>3087</td>\n      <td>55</td>\n      <td>6</td>\n      <td>1328</td>\n      <td>202</td>\n      <td>3132</td>\n      <td>224</td>\n      <td>227</td>\n      <td>139</td>\n      <td>1224</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>574300</th>\n      <td>2546</td>\n      <td>100</td>\n      <td>25</td>\n      <td>85</td>\n      <td>28</td>\n      <td>1897</td>\n      <td>252</td>\n      <td>196</td>\n      <td>57</td>\n      <td>553</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>267484</th>\n      <td>2879</td>\n      <td>276</td>\n      <td>16</td>\n      <td>300</td>\n      <td>-4</td>\n      <td>1396</td>\n      <td>175</td>\n      <td>242</td>\n      <td>206</td>\n      <td>1518</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397396</th>\n      <td>2977</td>\n      <td>113</td>\n      <td>16</td>\n      <td>912</td>\n      <td>182</td>\n      <td>2671</td>\n      <td>246</td>\n      <td>221</td>\n      <td>98</td>\n      <td>1598</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49723</th>\n      <td>2688</td>\n      <td>335</td>\n      <td>15</td>\n      <td>67</td>\n      <td>18</td>\n      <td>1290</td>\n      <td>184</td>\n      <td>218</td>\n      <td>173</td>\n      <td>3226</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>156845</th>\n      <td>2996</td>\n      <td>14</td>\n      <td>9</td>\n      <td>242</td>\n      <td>54</td>\n      <td>3878</td>\n      <td>212</td>\n      <td>222</td>\n      <td>147</td>\n      <td>2592</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>256753</th>\n      <td>2023</td>\n      <td>288</td>\n      <td>34</td>\n      <td>85</td>\n      <td>24</td>\n      <td>313</td>\n      <td>108</td>\n      <td>214</td>\n      <td>235</td>\n      <td>576</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>538388</th>\n      <td>3208</td>\n      <td>287</td>\n      <td>16</td>\n      <td>150</td>\n      <td>4</td>\n      <td>4129</td>\n      <td>173</td>\n      <td>237</td>\n      <td>204</td>\n      <td>1800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>389278 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "266280    3\n",
       "306815    1\n",
       "382286    2\n",
       "574300    6\n",
       "267484    2\n",
       "         ..\n",
       "397396    2\n",
       "49723     2\n",
       "156845    2\n",
       "256753    3\n",
       "538388    1\n",
       "Name: V55, Length: 389278, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['V55']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          V1   V2  V3    V4   V5    V6   V7   V8   V9   V10  ...  V46  V47  \\\n",
       "266280  2290  333  15   300   66   953  185  220  173   212  ...    0    0   \n",
       "306815  3244  109  19   134   18  1695  248  216   88  2914  ...    0    0   \n",
       "382286  3087   55   6  1328  202  3132  224  227  139  1224  ...    1    0   \n",
       "574300  2546  100  25    85   28  1897  252  196   57   553  ...    0    0   \n",
       "267484  2879  276  16   300   -4  1396  175  242  206  1518  ...    1    0   \n",
       "...      ...  ...  ..   ...  ...   ...  ...  ...  ...   ...  ...  ...  ...   \n",
       "397396  2977  113  16   912  182  2671  246  221   98  1598  ...    0    0   \n",
       "49723   2688  335  15    67   18  1290  184  218  173  3226  ...    0    0   \n",
       "156845  2996   14   9   242   54  3878  212  222  147  2592  ...    0    0   \n",
       "256753  2023  288  34    85   24   313  108  214  235   576  ...    0    0   \n",
       "538388  3208  287  16   150    4  4129  173  237  204  1800  ...    0    0   \n",
       "\n",
       "        V48  V49  V50  V51  V52  V53  V54  V55  \n",
       "266280    0    0    0    0    0    0    0    3  \n",
       "306815    0    0    0    0    0    1    0    1  \n",
       "382286    0    0    0    0    0    0    0    2  \n",
       "574300    0    0    0    0    0    0    0    6  \n",
       "267484    0    0    0    0    0    0    0    2  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "397396    0    0    0    0    0    0    0    2  \n",
       "49723     0    0    0    0    0    0    0    2  \n",
       "156845    0    0    0    0    0    0    0    2  \n",
       "256753    0    0    0    0    0    0    0    3  \n",
       "538388    0    0    0    0    0    0    0    1  \n",
       "\n",
       "[389278 rows x 55 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V46</th>\n      <th>V47</th>\n      <th>V48</th>\n      <th>V49</th>\n      <th>V50</th>\n      <th>V51</th>\n      <th>V52</th>\n      <th>V53</th>\n      <th>V54</th>\n      <th>V55</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>266280</th>\n      <td>2290</td>\n      <td>333</td>\n      <td>15</td>\n      <td>300</td>\n      <td>66</td>\n      <td>953</td>\n      <td>185</td>\n      <td>220</td>\n      <td>173</td>\n      <td>212</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>306815</th>\n      <td>3244</td>\n      <td>109</td>\n      <td>19</td>\n      <td>134</td>\n      <td>18</td>\n      <td>1695</td>\n      <td>248</td>\n      <td>216</td>\n      <td>88</td>\n      <td>2914</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>382286</th>\n      <td>3087</td>\n      <td>55</td>\n      <td>6</td>\n      <td>1328</td>\n      <td>202</td>\n      <td>3132</td>\n      <td>224</td>\n      <td>227</td>\n      <td>139</td>\n      <td>1224</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>574300</th>\n      <td>2546</td>\n      <td>100</td>\n      <td>25</td>\n      <td>85</td>\n      <td>28</td>\n      <td>1897</td>\n      <td>252</td>\n      <td>196</td>\n      <td>57</td>\n      <td>553</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>267484</th>\n      <td>2879</td>\n      <td>276</td>\n      <td>16</td>\n      <td>300</td>\n      <td>-4</td>\n      <td>1396</td>\n      <td>175</td>\n      <td>242</td>\n      <td>206</td>\n      <td>1518</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397396</th>\n      <td>2977</td>\n      <td>113</td>\n      <td>16</td>\n      <td>912</td>\n      <td>182</td>\n      <td>2671</td>\n      <td>246</td>\n      <td>221</td>\n      <td>98</td>\n      <td>1598</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49723</th>\n      <td>2688</td>\n      <td>335</td>\n      <td>15</td>\n      <td>67</td>\n      <td>18</td>\n      <td>1290</td>\n      <td>184</td>\n      <td>218</td>\n      <td>173</td>\n      <td>3226</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>156845</th>\n      <td>2996</td>\n      <td>14</td>\n      <td>9</td>\n      <td>242</td>\n      <td>54</td>\n      <td>3878</td>\n      <td>212</td>\n      <td>222</td>\n      <td>147</td>\n      <td>2592</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>256753</th>\n      <td>2023</td>\n      <td>288</td>\n      <td>34</td>\n      <td>85</td>\n      <td>24</td>\n      <td>313</td>\n      <td>108</td>\n      <td>214</td>\n      <td>235</td>\n      <td>576</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>538388</th>\n      <td>3208</td>\n      <td>287</td>\n      <td>16</td>\n      <td>150</td>\n      <td>4</td>\n      <td>4129</td>\n      <td>173</td>\n      <td>237</td>\n      <td>204</td>\n      <td>1800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>389278 rows × 55 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_balance=X_train.groupby('V55').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff94bee370>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 394.375 248.518125\" width=\"394.375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 394.375 248.518125 \r\nL 394.375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 52.375 224.64 \r\nL 387.175 224.64 \r\nL 387.175 7.2 \r\nL 52.375 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 57.157857 224.64 \r\nL 95.420714 224.64 \r\nL 95.420714 69.534335 \r\nL 57.157857 69.534335 \r\nz\r\n\" style=\"fill:#3274a1;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 104.986429 224.64 \r\nL 143.249286 224.64 \r\nL 143.249286 17.554286 \r\nL 104.986429 17.554286 \r\nz\r\n\" style=\"fill:#e1812c;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 152.815 224.64 \r\nL 191.077857 224.64 \r\nL 191.077857 198.599797 \r\nL 152.815 198.599797 \r\nz\r\n\" style=\"fill:#3a923a;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 200.643571 224.64 \r\nL 238.906429 224.64 \r\nL 238.906429 222.643788 \r\nL 200.643571 222.643788 \r\nz\r\n\" style=\"fill:#c03d3e;\"/>\r\n   </g>\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 248.472143 224.64 \r\nL 286.735 224.64 \r\nL 286.735 217.788521 \r\nL 248.472143 217.788521 \r\nz\r\n\" style=\"fill:#9372b2;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 296.300714 224.64 \r\nL 334.563571 224.64 \r\nL 334.563571 211.987507 \r\nL 296.300714 211.987507 \r\nz\r\n\" style=\"fill:#845b53;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path clip-path=\"url(#peca52d3a42)\" d=\"M 344.129286 224.64 \r\nL 382.392143 224.64 \r\nL 382.392143 209.737133 \r\nL 344.129286 209.737133 \r\nz\r\n\" style=\"fill:#d684bd;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mae22240098\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.289286\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 1 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(73.108036 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.117857\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(120.936607 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.946429\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 3 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(168.765179 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.775\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(216.59375 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"267.603571\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(264.422321 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"315.432143\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(312.250893 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.260714\" xlink:href=\"#mae22240098\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 7 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(360.079464 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"md5369aab20\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(39.0125 228.439219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"197.369346\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 25000 -->\r\n      <g transform=\"translate(13.5625 201.168564)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"170.098691\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 50000 -->\r\n      <g transform=\"translate(13.5625 173.89791)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"142.828037\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 75000 -->\r\n      <g transform=\"translate(13.5625 146.627255)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"115.557382\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 100000 -->\r\n      <g transform=\"translate(7.2 119.356601)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"88.286728\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 125000 -->\r\n      <g transform=\"translate(7.2 92.085946)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"61.016073\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 150000 -->\r\n      <g transform=\"translate(7.2 64.815292)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#md5369aab20\" y=\"33.745419\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 175000 -->\r\n      <g transform=\"translate(7.2 37.544637)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_19\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_20\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_21\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"line2d_22\">\r\n    <path clip-path=\"url(#peca52d3a42)\" style=\"fill:none;stroke:#424242;stroke-linecap:square;stroke-width:2.7;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 52.375 224.64 \r\nL 52.375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 387.175 224.64 \r\nL 387.175 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 52.375 224.64 \r\nL 387.175 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_13\">\r\n    <path d=\"M 52.375 7.2 \r\nL 387.175 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"peca52d3a42\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"52.375\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWCklEQVR4nO3df6ye5X3f8fenOGUkLYQfToRsMpNAoyZ0c8qRw4SSsroFJ8sCmWA1WoO3MTlBUCVKtS00UsmIkMaqlIl1oXJijx9N+FEoglXQxApdWCsCHCcs5kcYJiHhBA/cmBGyFCqT7/54rhM9No+v88s+DwfeL+nWcz/f+77u832Q0Ofc13U/x6kqJEnan58bdwOSpFc2g0KS1GVQSJK6DApJUpdBIUnqWjbuBg60Y445platWjXuNiRpSdm2bdvfVNXyUcdedUGxatUqJicnx92GJC0pSb63v2NOPUmSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkrpedd/MfjX6/qW/Mu4WRnrL728fdwuSFoF3FJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklS14xBkWRLkmeSPDhUuzHJA217IskDrb4qyd8OHfvjoTEnJ9meZEeSK5Ok1Q9t19uR5N4kq4bGbEjyWNs2HMgPLkmandn89dirgT8Crp0uVNVvTe8n+Szw3ND5j1fV6hHXuQrYCHwduANYB9wJnA88W1UnJFkPXA78VpKjgEuACaCAbUlur6pnZ//xJEkLNeMdRVXdDewedazdFfxz4PreNZIcCxxeVfdUVTEInbPa4TOBa9r+zcDadt0zgK1VtbuFw1YG4SJJWkQLXaN4D/B0VT02VDs+yTeTfC3Je1ptBTA1dM5Uq00fexKgqvYwuDs5erg+YsxekmxMMplkcteuXQv8SJKkYQsNinPZ+25iJ/CWqnoX8AngS0kOBzJibLXX/R3rjdm7WLWpqiaqamL58uWzbl6SNLN5B0WSZcA/A26crlXVi1X1w7a/DXgc+CUGdwMrh4avBJ5q+1PAcUPXPILBVNfP6iPGSJIWyULuKH4D+HZV/WxKKcnyJIe0/bcCJwLfqaqdwPNJTmnrD+cBt7VhtwPTTzSdDdzV1jG+DJye5MgkRwKnt5okaRHN+NRTkuuB04BjkkwBl1TVZmA9L1/Efi9waZI9wEvAR6tqeiH8AgZPUB3G4GmnO1t9M3Bdkh0M7iTWA1TV7iSfAe5v5106dC1J0iKZMSiq6tz91P/liNotwC37OX8SOGlE/QXgnP2M2QJsmalHSdLB4zezJUldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpa8agSLIlyTNJHhyqfTrJD5I80Lb3Dx27OMmOJI8mOWOofnKS7e3YlUnS6ocmubHV702yamjMhiSPtW3DgfrQkqTZm80dxdXAuhH1K6pqddvuAEjyDmA98M425nNJDmnnXwVsBE5s2/Q1zweeraoTgCuAy9u1jgIuAd4NrAEuSXLknD+hJGlBZgyKqrob2D3L650J3FBVL1bVd4EdwJokxwKHV9U9VVXAtcBZQ2Ouafs3A2vb3cYZwNaq2l1VzwJbGR1YkqSDaCFrFBcl+Vabmpr+TX8F8OTQOVOttqLt71vfa0xV7QGeA47uXOtlkmxMMplkcteuXQv4SJKkfc03KK4C3gasBnYCn231jDi3OvX5jtm7WLWpqiaqamL58uW9viVJczSvoKiqp6vqpar6KfB5BmsIMPit/7ihU1cCT7X6yhH1vcYkWQYcwWCqa3/XkiQtonkFRVtzmPYhYPqJqNuB9e1JpuMZLFrfV1U7geeTnNLWH84DbhsaM/1E09nAXW0d48vA6UmObFNbp7eaJGkRLZvphCTXA6cBxySZYvAk0mlJVjOYCnoC+AhAVT2U5CbgYWAPcGFVvdQudQGDJ6gOA+5sG8Bm4LokOxjcSaxv19qd5DPA/e28S6tqtovqkqQDJINf3l89JiYmanJyctxtHFDfv/RXxt3CSG/5/e3jbkHSAZJkW1VNjDrmN7MlSV0GhSSpy6CQJHXNuJj9anDyv7123C2MtO0Pzht3C5I0I+8oJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6ZgyKJFuSPJPkwaHaHyT5dpJvJbk1yRtbfVWSv03yQNv+eGjMyUm2J9mR5MokafVDk9zY6vcmWTU0ZkOSx9q24UB+cEnS7MzmjuJqYN0+ta3ASVX1D4D/DVw8dOzxqlrdto8O1a8CNgIntm36mucDz1bVCcAVwOUASY4CLgHeDawBLkly5Bw+myTpAJgxKKrqbmD3PrWvVNWe9vbrwMreNZIcCxxeVfdUVQHXAme1w2cC17T9m4G17W7jDGBrVe2uqmcZhNO+gSVJOsgOxBrFvwbuHHp/fJJvJvlakve02gpgauicqVabPvYkQAuf54Cjh+sjxuwlycYkk0kmd+3atdDPI0kasqCgSPIpYA/wxVbaCbylqt4FfAL4UpLDgYwYXtOX2c+x3pi9i1WbqmqiqiaWL18+l48gSZrBvIOiLS5/APgXbTqJqnqxqn7Y9rcBjwO/xOBuYHh6aiXwVNufAo5r11wGHMFgqutn9RFjJEmLZF5BkWQd8O+BD1bVT4bqy5Mc0vbfymDR+jtVtRN4Pskpbf3hPOC2Nux2YPqJprOBu1rwfBk4PcmRbRH79FaTJC2iZTOdkOR64DTgmCRTDJ5Euhg4FNjannL9envC6b3ApUn2AC8BH62q6YXwCxg8QXUYgzWN6XWNzcB1SXYwuJNYD1BVu5N8Bri/nXfp0LUkSYtkxqCoqnNHlDfv59xbgFv2c2wSOGlE/QXgnP2M2QJsmalHSdLB4zezJUldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHXNGBRJtiR5JsmDQ7WjkmxN8lh7PXLo2MVJdiR5NMkZQ/WTk2xvx65MklY/NMmNrX5vklVDYza0n/FYkg0H6kNLkmZvNncUVwPr9ql9EvhqVZ0IfLW9J8k7gPXAO9uYzyU5pI25CtgInNi26WueDzxbVScAVwCXt2sdBVwCvBtYA1wyHEiSpMUxY1BU1d3A7n3KZwLXtP1rgLOG6jdU1YtV9V1gB7AmybHA4VV1T1UVcO0+Y6avdTOwtt1tnAFsrardVfUssJWXB5Yk6SCb7xrFm6tqJ0B7fVOrrwCeHDpvqtVWtP1963uNqao9wHPA0Z1rvUySjUkmk0zu2rVrnh9JkjTKgV7MzohaderzHbN3sWpTVU1U1cTy5ctn1agkaXbmGxRPt+kk2uszrT4FHDd03krgqVZfOaK+15gky4AjGEx17e9akqRFNN+guB2YfgppA3DbUH19e5LpeAaL1ve16annk5zS1h/O22fM9LXOBu5q6xhfBk5PcmRbxD691SRJi2jZTCckuR44DTgmyRSDJ5H+I3BTkvOB7wPnAFTVQ0luAh4G9gAXVtVL7VIXMHiC6jDgzrYBbAauS7KDwZ3E+nat3Uk+A9zfzru0qvZdVJckHWQzBkVVnbufQ2v3c/5lwGUj6pPASSPqL9CCZsSxLcCWmXqUJB08fjNbktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK65h0USd6e5IGh7UdJPp7k00l+MFR//9CYi5PsSPJokjOG6icn2d6OXZkkrX5okhtb/d4kqxbyYSVJczfvoKiqR6tqdVWtBk4GfgLc2g5fMX2squ4ASPIOYD3wTmAd8Lkkh7TzrwI2Aie2bV2rnw88W1UnAFcAl8+3X0nS/Byoqae1wONV9b3OOWcCN1TVi1X1XWAHsCbJscDhVXVPVRVwLXDW0Jhr2v7NwNrpuw1J0uI4UEGxHrh+6P1FSb6VZEuSI1ttBfDk0DlTrbai7e9b32tMVe0BngOO3veHJ9mYZDLJ5K5duw7E55EkNQsOiiQ/D3wQ+NNWugp4G7Aa2Al8dvrUEcOrU++N2btQtamqJqpqYvny5XPoXpI0kwNxR/E+4BtV9TRAVT1dVS9V1U+BzwNr2nlTwHFD41YCT7X6yhH1vcYkWQYcAew+AD1LkmbpQATFuQxNO7U1h2kfAh5s+7cD69uTTMczWLS+r6p2As8nOaWtP5wH3DY0ZkPbPxu4q61jSJIWybKFDE7yeuA3gY8Mlf9TktUMpoiemD5WVQ8luQl4GNgDXFhVL7UxFwBXA4cBd7YNYDNwXZIdDO4k1i+kX0nS3C0oKKrqJ+yzuFxVH+6cfxlw2Yj6JHDSiPoLwDkL6VGStDB+M1uS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroWFBRJnkiyPckDSSZb7agkW5M81l6PHDr/4iQ7kjya5Iyh+sntOjuSXJkkrX5okhtb/d4kqxbSryRp7g7EHcU/rqrVVTXR3n8S+GpVnQh8tb0nyTuA9cA7gXXA55Ic0sZcBWwETmzbulY/H3i2qk4ArgAuPwD9SpLm4GBMPZ0JXNP2rwHOGqrfUFUvVtV3gR3AmiTHAodX1T1VVcC1+4yZvtbNwNrpuw1J0uJYaFAU8JUk25JsbLU3V9VOgPb6plZfATw5NHaq1Va0/X3re42pqj3Ac8DR+zaRZGOSySSTu3btWuBHkiQNW7bA8adW1VNJ3gRsTfLtzrmj7gSqU++N2btQtQnYBDAxMfGy45Kk+VvQHUVVPdVenwFuBdYAT7fpJNrrM+30KeC4oeErgadafeWI+l5jkiwDjgB2L6RnSdLczDsokrwhyS9O7wOnAw8CtwMb2mkbgNva/u3A+vYk0/EMFq3va9NTzyc5pa0/nLfPmOlrnQ3c1dYxJEmLZCFTT28Gbm1ry8uAL1XVXyS5H7gpyfnA94FzAKrqoSQ3AQ8De4ALq+qldq0LgKuBw4A72wawGbguyQ4GdxLrF9CvJGke5h0UVfUd4B+OqP8QWLufMZcBl42oTwInjai/QAsaSdJ4+M1sSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqmndQJDkuyV8meSTJQ0k+1uqfTvKDJA+07f1DYy5OsiPJo0nOGKqfnGR7O3Zl2j/EneTQJDe2+r1JVs3/o0qS5mMhdxR7gN+tql8GTgEuTPKOduyKqlrdtjsA2rH1wDuBdcDnkhzSzr8K2Aic2LZ1rX4+8GxVnQBcAVy+gH4lSfMw76Coqp1V9Y22/zzwCLCiM+RM4IaqerGqvgvsANYkORY4vKruqaoCrgXOGhpzTdu/GVg7fbchSVocB2SNok0JvQu4t5UuSvKtJFuSHNlqK4Anh4ZNtdqKtr9vfa8xVbUHeA44+kD0LEmanQUHRZJfAG4BPl5VP2IwjfQ2YDWwE/js9Kkjhlen3huzbw8bk0wmmdy1a9ccP4EkqWfZQgYneR2DkPhiVf0ZQFU9PXT888Cft7dTwHFDw1cCT7X6yhH14TFTSZYBRwC79+2jqjYBmwAmJiZeFiQar1P/y6njbmGkv/6dvx53C9KSsJCnngJsBh6pqj8cqh87dNqHgAfb/u3A+vYk0/EMFq3vq6qdwPNJTmnXPA+4bWjMhrZ/NnBXW8eQJC2ShdxRnAp8GNie5IFW+z3g3CSrGUwRPQF8BKCqHkpyE/AwgyemLqyql9q4C4CrgcOAO9sGgyC6LskOBncS6xfQryRpHuYdFFX1V4xeQ7ijM+Yy4LIR9UngpBH1F4Bz5tujJGnh/Ga2JKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqWtCf8JAk7d8jl9017hZG+uVP/fqczveOQpLU5R2FpFesy3777HG3sF+f+pObx93CovGOQpLUZVBIkroMCklSl0EhSeoyKCRJXT71JL3K/dHv/vdxtzDSRZ/9p+NuQbPkHYUkqcugkCR1GRSSpK4lERRJ1iV5NMmOJJ8cdz+S9Fryil/MTnII8F+B3wSmgPuT3F5VD4+3M71WfO29vzbuFkb6tbu/Nu4W9BqxFO4o1gA7quo7VfV3wA3AmWPuSZJeM1JV4+6hK8nZwLqq+jft/YeBd1fVRUPnbAQ2trdvBx49iC0dA/zNQbz+wWb/42X/47WU+z/Yvf/9qlo+6sArfuoJyIjaXulWVZuATYvSTDJZVROL8bMOBvsfL/sfr6Xc/zh7XwpTT1PAcUPvVwJPjakXSXrNWQpBcT9wYpLjk/w8sB64fcw9SdJrxit+6qmq9iS5CPgycAiwpaoeGmNLizLFdRDZ/3jZ/3gt5f7H1vsrfjFbkjReS2HqSZI0RgaFJKnLoJilJFuSPJPkwXH3Mh9Jjkvyl0keSfJQko+Nu6e5SPL3ktyX5H+1/v/DuHuaqySHJPlmkj8fdy9zleSJJNuTPJBkctz9zFWSNya5Ocm32/8D/2jcPc1Wkre3/+7T24+SfHxRe3CNYnaSvBf4MXBtVZ007n7mKsmxwLFV9Y0kvwhsA85aKn8KJUmAN1TVj5O8Dvgr4GNV9fUxtzZrST4BTACHV9UHxt3PXCR5ApioqiX5ZbUk1wD/s6q+0J6efH1V/d9x9zVX7U8a/YDBl46/t1g/1zuKWaqqu4Hd4+5jvqpqZ1V9o+0/DzwCrBhvV7NXAz9ub1/XtiXzW06SlcA/Ab4w7l5ea5IcDrwX2AxQVX+3FEOiWQs8vpghAQbFa1KSVcC7gHvH28nctKmbB4BngK1VtZT6/8/AvwN+Ou5G5qmAryTZ1v5kzlLyVmAX8N/a1N8Xkrxh3E3N03rg+sX+oQbFa0ySXwBuAT5eVT8adz9zUVUvVdVqBt/OX5NkSUwBJvkA8ExVbRt3LwtwalX9KvA+4MI2FbtULAN+Fbiqqt4F/D9gyf1zBW3K7IPAny72zzYoXkPa3P4twBer6s/G3c98tWmD/wGsG3Mrs3Uq8ME2z38D8OtJ/mS8Lc1NVT3VXp8BbmXwV52XiilgaugO9GYGwbHUvA/4RlU9vdg/2KB4jWiLwZuBR6rqD8fdz1wlWZ7kjW3/MOA3gG+Pt6vZqaqLq2plVa1iMHVwV1X99pjbmrUkb2gPQNCmbE4HlszTf1X1f4Ank7y9ldYCS+Ihjn2cyximnWAJ/AmPV4ok1wOnAcckmQIuqarN4+1qTk4FPgxsb/P8AL9XVXeMsae5OBa4pj318XPATVW15B4zXaLeDNw6+F2DZcCXquovxtvSnP0O8MU2ffMd4F+NuZ85SfJ6Bv9420fG8vN9PFaS1OPUkySpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6vr/kAy5mUwToh0AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plt.plot(Make_balance, type='bar')\n",
    "sns.barplot(x=[1,2,3,4,5,6,7] ,y=Make_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "V55\n",
       "1    36.526852\n",
       "2    48.767976\n",
       "3     6.132378\n",
       "4     0.470101\n",
       "5     1.613500\n",
       "6     2.979619\n",
       "7     3.509574\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "Make_balance/sum(Make_balance)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "type(X_train[X_train['V55']==4].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "arr_sampled_train=[]\n",
    "\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==1].index.values.tolist(),360))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==2].index.values.tolist(),480))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==3].index.values.tolist(),60))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==4].index.values.tolist(),10))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==5].index.values.tolist(),16))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==6].index.values.tolist(),30))\n",
    "arr_sampled_train.append(random.sample(X_train[X_train['V55']==7].index.values.tolist(),35))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([13054,  3138,  6078, ...,  4191,  4850,  5472], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X_train[X_train['V55']==4].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr_sampled_train=np.concatenate(arr_sampled_train, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 34230, 123477, 419850, 464416,  46694, 196077,  16267, 509742,\n",
       "       398930, 417097,  60487, 210119, 193511, 526954,  33842, 221843,\n",
       "        39353, 353197, 208563, 481999, 427081, 401899, 552569, 197253,\n",
       "       101962,  72297, 429432, 421813, 329845, 304360, 266857, 168310,\n",
       "       557055, 449698, 531709, 154746, 539384, 386721, 398567, 460672,\n",
       "       319006, 313775, 391151,  10390, 518715, 513057, 449403, 534301,\n",
       "       161306, 148228, 256249, 282865, 511648, 240866, 158222, 510647,\n",
       "       414973,  36617, 159267, 407939, 188805, 450372, 421208, 400672,\n",
       "       214917, 307505, 231853, 228748, 362848, 179495, 551435, 269798,\n",
       "       279226, 255097, 325177,  51530, 500932, 466191,  40876, 386454,\n",
       "       204361, 402722, 528349, 439784, 511608, 392506, 273044, 133506,\n",
       "       560211,  59615, 562040, 525671, 316478,  99450, 506915, 438154,\n",
       "       416252, 305528,  59659, 262455, 431686, 494933, 477024, 331147,\n",
       "       352503, 340283, 127372, 344163, 429527, 260823, 325868, 451652,\n",
       "       378182, 487415, 455272, 242769,  81399, 388063, 394222, 134956,\n",
       "       356488, 108622,  49446, 207686, 239813, 435053, 346007, 445406,\n",
       "       379958, 295625, 307358, 333783, 310933,  36214, 463425, 165770,\n",
       "       264262, 153757, 534264, 126188,  72902, 518018, 294654, 448392,\n",
       "       505845, 190684, 146029, 416869, 429054, 333574, 162518, 389887,\n",
       "       387818, 549001, 363591, 543782, 413643, 187216, 314389, 271435,\n",
       "       181789, 199804, 522418, 310961, 148824, 486426, 351968, 518808,\n",
       "       412900, 490274, 326511, 273411, 527850, 199207, 346534,  70451,\n",
       "        65799,  30428, 451084, 444363, 490959, 326277, 379468, 345935,\n",
       "       536894, 451067, 538449,  27792, 420619, 189754, 455522, 324944,\n",
       "       193396, 520997, 339819, 167617, 263304, 482451, 304396, 201212,\n",
       "       342280, 440126, 473893, 257564, 537715,  42426, 467311,  23144,\n",
       "       206475, 261429, 326548, 301407, 389867, 267541, 126313, 551586,\n",
       "       234677, 440150,  71366, 520037, 432244, 158762,  64257, 304481,\n",
       "        56607, 521079, 504845, 523393, 324520, 366610,  99721, 395185,\n",
       "        40449,  61055, 432077, 544497, 564863, 386605, 305801, 419885,\n",
       "       383221, 172116, 210675, 300661, 562715, 102825, 201592, 438869,\n",
       "       468020, 289489, 562904, 525945, 392554, 392405, 356162, 383434,\n",
       "       304424, 316268, 392529, 410642, 530832, 121212, 399709, 366474,\n",
       "       380583, 500565, 512326, 163097, 251074, 534558, 522072, 462826,\n",
       "       121002, 320078, 408735, 503142, 490581, 511478, 485673, 270343,\n",
       "       421537,  99987, 156275, 392875, 313468, 527013,  63260, 185839,\n",
       "       326500,  76586, 417596, 500668, 180510, 155045, 440568,  72604,\n",
       "       344200,  61883, 388389, 430086,  54745, 395801, 545362, 264282,\n",
       "        45551, 493654, 293294, 437689, 305040, 512787,  26146, 561677,\n",
       "       177591, 362258, 416974,  58696, 493924, 538088,  59332, 208144,\n",
       "       430925, 511063, 466693,  14140, 514097, 457292, 422102, 514518,\n",
       "       430093, 355008, 303057, 542609, 519699, 104634, 355802, 459204,\n",
       "        98335, 518283, 408519,  37018,  42394, 327257, 486351, 429597,\n",
       "       209414, 193919, 510681, 466182, 124847, 399721, 461790, 450582,\n",
       "       323090, 134344,  97762, 439214, 183154,  66813, 452528, 157219,\n",
       "       267519, 127473, 176424, 461915,  99059, 223667,  44045, 543318,\n",
       "       524029, 246305, 302596,  91744, 256025, 169049, 333232, 441202,\n",
       "       376882, 485452, 109069, 536550, 443256, 497308, 150533, 347240,\n",
       "          867, 425863, 556522,  16903,  81414, 267551, 367631, 248412,\n",
       "        32053, 281710, 429739, 521419, 559529, 525970, 549044,  60357,\n",
       "       173620,  23040,  76223, 344896, 378962,  51327, 310982, 115664,\n",
       "        44185, 555600,  45222,  38441, 356676, 471798, 321346, 465462,\n",
       "       457860,  43717, 225199,  60648, 179639, 178571,  87317, 336384,\n",
       "       392323, 186641,  49494, 237202, 247916, 415190, 446075, 235748,\n",
       "       129154,    109,  80588, 175729,  26177, 149880, 270452, 253922,\n",
       "       550985,  22882, 170503, 253592, 567099, 533035, 391419,  95313,\n",
       "       463946, 167145, 303017, 180973, 489180, 361130, 518413, 246381,\n",
       "       312119, 318609, 131064,  83375, 333524, 239526,  59555, 388220,\n",
       "       103243, 554049, 341685, 470682, 250405, 294729, 494424,  20621,\n",
       "       374317,  50455,  74324, 358150, 480230,  81854, 417964, 506275,\n",
       "       428314,  48167, 236087, 245367,  95710,  25727, 394938,  50269,\n",
       "       526351, 554294, 520773, 527336, 514667, 200190, 475554, 413240,\n",
       "       305954,  61918, 455914, 564574, 140997, 267038,  73667, 301223,\n",
       "       172267,    540, 170069, 330411, 359995, 348652, 241884, 324972,\n",
       "        84571, 367675, 170483, 139694,  46212, 134782, 320212, 164381,\n",
       "        27291, 233342, 436770, 423418, 147414,  81737, 275215, 472631,\n",
       "       168693, 426814, 161674, 209853, 403505, 159344, 555820, 150193,\n",
       "        19988,  86763, 164986, 521237, 305535, 352826, 356301, 196269,\n",
       "       253912, 232670, 100290, 136069,  76559, 370466,  76737, 253425,\n",
       "       234251,  23239, 297650, 204586, 371494, 533368,  97644,  46981,\n",
       "       544294, 361400, 569861, 141214, 259213,  58171,  68893, 303082,\n",
       "       517956, 119716, 408096, 373716, 322612, 330165, 355343, 250482,\n",
       "       257736, 241344,  49721,  53773, 384586, 344597, 560645, 424821,\n",
       "       503313, 473151, 568579,  83945, 552691,  46186,  74953, 507090,\n",
       "       369802, 376357, 169661, 299181, 146920, 200211, 377324, 225251,\n",
       "       133342, 529216, 479713, 152149,  68936, 421137,  76121, 163372,\n",
       "        92683, 221366,  43297, 228821, 389449, 337128, 116459,  84869,\n",
       "        44178,  69355, 134067, 427804, 562313,  29498, 249057, 407403,\n",
       "       309022, 113652, 567760, 200480, 133172, 240489, 113182, 510804,\n",
       "        61542, 157124, 170497, 131313, 554597, 388211, 137550, 439685,\n",
       "       115297,  96264, 122820, 130191, 156841,  56496, 232741, 549074,\n",
       "       244407, 218497, 483206, 306556, 195508, 531314, 368009, 141701,\n",
       "       237638, 172011, 120195, 324388, 332321, 178017, 429817, 500380,\n",
       "       307095,   6959, 398670, 174155, 403698, 393847, 555492,  83831,\n",
       "       389488,  57922, 186174,  43075, 469203, 542311, 510330, 115404,\n",
       "        72671,  32713,  36274, 238126, 209334,  72435, 105330,  18489,\n",
       "       326792, 547472, 108866, 218459, 169308, 370606, 342044, 130393,\n",
       "       340107, 383621, 217748, 257551, 138626, 217164, 100146,  87351,\n",
       "       221541,  30057, 100497, 172573, 170761, 201338, 324499, 430169,\n",
       "        66651, 424302, 194058, 194049,  66753, 457919, 500941,  61752,\n",
       "        68646, 138575,  97058,  96862, 338674,  98829, 504255, 251509,\n",
       "       129731, 134307, 235600, 296185,  84611, 387609,  24163, 541866,\n",
       "       364668, 317265, 141880, 117687,  36672,  69563, 224602, 369691,\n",
       "       285002,  36426, 266626,  90830, 454885, 189019,  41014, 248078,\n",
       "        66910, 106771,  69948, 141938, 151697, 468338, 324674,  95113,\n",
       "       233321, 507335, 422533, 564629, 459924, 141316,  21909, 397370,\n",
       "       238471, 534922,  29377, 318708, 162184, 147210, 376671, 200815,\n",
       "        95465, 476375,  49520, 364882, 244266, 184611, 468361, 106260,\n",
       "       342690, 266527, 368669, 165201, 201078,  32190, 144173, 124275,\n",
       "        99481, 382981, 216838, 238467, 486493, 415226,  76657, 567448,\n",
       "        19080, 260964, 376351,  75551, 484540, 206972, 371461, 377306,\n",
       "       319543, 401478, 482096, 493855, 191671, 204475, 565164, 560390,\n",
       "       108948, 543964, 230742,  50445, 151336, 285111, 220137, 561767,\n",
       "       134376, 149578,  50788, 406224,  57003,  68886,  40675,  99634,\n",
       "        34745, 100634,  19305, 432065, 183034, 304526, 350391, 200988,\n",
       "       577183, 291150, 294152, 246621, 577643, 253759, 248742, 576872,\n",
       "       292597, 263095, 254877, 271805, 571721, 231073, 280123, 248852,\n",
       "        11317, 276156, 260627, 233017, 243039, 269688, 260034, 263604,\n",
       "       282982, 260686, 371639, 377082,   7091,   2317, 390883, 239791,\n",
       "       394095, 226256, 576127, 257379, 572800, 296865, 351766, 282498,\n",
       "       579449, 335983, 578426, 251243,   4038, 577993, 293076, 574089,\n",
       "       247196, 359198, 577333, 316147, 280120, 266296, 279636, 271734,\n",
       "       403605, 580381, 576034, 558445,   2481,   3825,   2962,  12471,\n",
       "         5188,   5957, 269098, 276071,   3150, 271196, 400343, 171529,\n",
       "       113983, 187106, 242150, 275313,  72764,  11364, 261535, 312417,\n",
       "         2307, 358464, 332365, 340134, 326738, 241218, 228137, 359766,\n",
       "       359764, 255598, 573722, 413221,  10679, 283693, 245069, 304240,\n",
       "       565916, 305750, 296485, 272819, 238744, 288245, 237874, 567831,\n",
       "       575742, 238275, 419667, 290279, 296306, 365639, 273360, 227585,\n",
       "         5773, 577750, 290261, 576374, 458735, 482668, 533634, 391300,\n",
       "       270288, 344089, 358927, 477061, 500201, 340876,   6681,   8952,\n",
       "       458096, 542934, 394427, 215237, 475174, 402596, 501295, 371688,\n",
       "       379526, 476739, 389393, 262803, 469983, 228251, 343461, 448011,\n",
       "       462138, 376116, 465123, 486220, 481467, 289366,   9307])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "arr_sampled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_sampled_train\n",
    "X_train_conv=X_train.loc[arr_sampled_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          V1   V2  V3   V4   V5    V6   V7   V8   V9   V10  ...  V46  V47  \\\n",
       "34230   3168   75  13  255  101  4919  235  216  110  1611  ...    0    0   \n",
       "123477  2837  139   5    0    0  5110  228  238  144   335  ...    0    0   \n",
       "419850  3257  345  16  256   29  1620  187  213  164   752  ...    0    0   \n",
       "464416  2832   31   6  124    6   706  219  228  145   518  ...    1    0   \n",
       "46694   3241  344   8  759   50  3756  205  228  162  2430  ...    0    0   \n",
       "...      ...  ...  ..  ...  ...   ...  ...  ...  ...   ...  ...  ...  ...   \n",
       "465123  3397    0  18  618  208  4092  190  203  147  3586  ...    0    0   \n",
       "486220  3276  116  22  532  119  1090  251  213   78  1182  ...    0    0   \n",
       "481467  3451  283  16  865  255  4861  173  239  205  3001  ...    0    0   \n",
       "289366  3305   87  15  190   52  4043  241  215  100  4024  ...    0    0   \n",
       "9307    3332  359  19  573  186  3811  189  202  148  3593  ...    0    0   \n",
       "\n",
       "        V48  V49  V50  V51  V52  V53  V54  V55  \n",
       "34230     0    0    0    0    0    0    0    1  \n",
       "123477    0    0    0    0    0    0    0    1  \n",
       "419850    0    0    0    0    0    0    0    1  \n",
       "464416    0    0    0    0    0    0    0    1  \n",
       "46694     0    0    0    0    0    0    0    1  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "465123    0    0    0    0    0    0    1    7  \n",
       "486220    0    0    0    0    0    0    1    7  \n",
       "481467    0    0    0    0    0    1    0    7  \n",
       "289366    0    0    0    0    1    0    0    7  \n",
       "9307      0    0    0    0    0    0    1    7  \n",
       "\n",
       "[991 rows x 55 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>...</th>\n      <th>V46</th>\n      <th>V47</th>\n      <th>V48</th>\n      <th>V49</th>\n      <th>V50</th>\n      <th>V51</th>\n      <th>V52</th>\n      <th>V53</th>\n      <th>V54</th>\n      <th>V55</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34230</th>\n      <td>3168</td>\n      <td>75</td>\n      <td>13</td>\n      <td>255</td>\n      <td>101</td>\n      <td>4919</td>\n      <td>235</td>\n      <td>216</td>\n      <td>110</td>\n      <td>1611</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>123477</th>\n      <td>2837</td>\n      <td>139</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5110</td>\n      <td>228</td>\n      <td>238</td>\n      <td>144</td>\n      <td>335</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>419850</th>\n      <td>3257</td>\n      <td>345</td>\n      <td>16</td>\n      <td>256</td>\n      <td>29</td>\n      <td>1620</td>\n      <td>187</td>\n      <td>213</td>\n      <td>164</td>\n      <td>752</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>464416</th>\n      <td>2832</td>\n      <td>31</td>\n      <td>6</td>\n      <td>124</td>\n      <td>6</td>\n      <td>706</td>\n      <td>219</td>\n      <td>228</td>\n      <td>145</td>\n      <td>518</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46694</th>\n      <td>3241</td>\n      <td>344</td>\n      <td>8</td>\n      <td>759</td>\n      <td>50</td>\n      <td>3756</td>\n      <td>205</td>\n      <td>228</td>\n      <td>162</td>\n      <td>2430</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465123</th>\n      <td>3397</td>\n      <td>0</td>\n      <td>18</td>\n      <td>618</td>\n      <td>208</td>\n      <td>4092</td>\n      <td>190</td>\n      <td>203</td>\n      <td>147</td>\n      <td>3586</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>486220</th>\n      <td>3276</td>\n      <td>116</td>\n      <td>22</td>\n      <td>532</td>\n      <td>119</td>\n      <td>1090</td>\n      <td>251</td>\n      <td>213</td>\n      <td>78</td>\n      <td>1182</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>481467</th>\n      <td>3451</td>\n      <td>283</td>\n      <td>16</td>\n      <td>865</td>\n      <td>255</td>\n      <td>4861</td>\n      <td>173</td>\n      <td>239</td>\n      <td>205</td>\n      <td>3001</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>289366</th>\n      <td>3305</td>\n      <td>87</td>\n      <td>15</td>\n      <td>190</td>\n      <td>52</td>\n      <td>4043</td>\n      <td>241</td>\n      <td>215</td>\n      <td>100</td>\n      <td>4024</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9307</th>\n      <td>3332</td>\n      <td>359</td>\n      <td>19</td>\n      <td>573</td>\n      <td>186</td>\n      <td>3811</td>\n      <td>189</td>\n      <td>202</td>\n      <td>148</td>\n      <td>3593</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>991 rows × 55 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X_train_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_conv.to_csv('./Data/Q_4_train_conv.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_20=X_train_conv[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]\n",
    "X_test20 = X_test[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          V1  V3   V5    V6  V12  V14  V16  V19  V20  V24  V25  V26  V27  V28  \\\n",
       "34230   3168  13  101  4919    0    0    0    0    0    0    0    0    0    0   \n",
       "123477  2837   5    0  5110    0    0    0    0    0    0    0    0    0    0   \n",
       "419850  3257  16   29  1620    0    0    0    0    0    0    0    0    0    0   \n",
       "464416  2832   6    6   706    0    0    0    0    0    0    0    0    0    0   \n",
       "46694   3241   8   50  3756    0    0    0    0    0    0    0    0    0    0   \n",
       "...      ...  ..  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "465123  3397  18  208  4092    0    0    0    0    0    0    0    0    0    0   \n",
       "486220  3276  22  119  1090    0    0    0    0    0    0    0    0    0    0   \n",
       "481467  3451  16  255  4861    0    0    0    0    0    0    0    0    0    0   \n",
       "289366  3305  15   52  4043    0    0    0    0    0    0    0    0    0    0   \n",
       "9307    3332  19  186  3811    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "        V30  V31  V34  V43  V44  V46  \n",
       "34230     0    0    0    1    0    0  \n",
       "123477    0    0    0    0    0    0  \n",
       "419850    0    0    0    0    0    0  \n",
       "464416    0    0    0    0    0    1  \n",
       "46694     0    0    0    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  \n",
       "465123    0    0    0    0    0    0  \n",
       "486220    0    0    0    0    0    0  \n",
       "481467    0    0    0    0    0    0  \n",
       "289366    0    0    0    0    0    0  \n",
       "9307      0    0    0    0    0    0  \n",
       "\n",
       "[991 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V3</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V12</th>\n      <th>V14</th>\n      <th>V16</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V34</th>\n      <th>V43</th>\n      <th>V44</th>\n      <th>V46</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34230</th>\n      <td>3168</td>\n      <td>13</td>\n      <td>101</td>\n      <td>4919</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>123477</th>\n      <td>2837</td>\n      <td>5</td>\n      <td>0</td>\n      <td>5110</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>419850</th>\n      <td>3257</td>\n      <td>16</td>\n      <td>29</td>\n      <td>1620</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>464416</th>\n      <td>2832</td>\n      <td>6</td>\n      <td>6</td>\n      <td>706</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46694</th>\n      <td>3241</td>\n      <td>8</td>\n      <td>50</td>\n      <td>3756</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465123</th>\n      <td>3397</td>\n      <td>18</td>\n      <td>208</td>\n      <td>4092</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>486220</th>\n      <td>3276</td>\n      <td>22</td>\n      <td>119</td>\n      <td>1090</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>481467</th>\n      <td>3451</td>\n      <td>16</td>\n      <td>255</td>\n      <td>4861</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>289366</th>\n      <td>3305</td>\n      <td>15</td>\n      <td>52</td>\n      <td>4043</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9307</th>\n      <td>3332</td>\n      <td>19</td>\n      <td>186</td>\n      <td>3811</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>991 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "X_train_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train_10=X_train_conv[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "x_train_10_all=X_train_conv[['V1',  'V7', 'V13', 'V14', 'V24', 'V49', 'V51', 'V52', 'V53', 'V54' ]]\n",
    "\n",
    "X_test_10 = X_test[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "x_test_10_all=X_test[['V1',  'V7', 'V13', 'V14', 'V24', 'V49', 'V51', 'V52', 'V53', 'V54' ]]\n",
    "\n",
    "\n",
    "X_train_20=X_train_conv[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]\n",
    "X_test_20 = X_test[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model_L_10 = LogisticRegression()\n",
    "model_L_10.fit(X_train_10, X_train_conv[['V55']])\n",
    "Test_y_hat=model_L_10.predict(X_test_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L_20 = LogisticRegression()\n",
    "model_L_20.fit(X_train_20, X_train_conv[['V55']])\n",
    "Test_y_hat_20=model_L_20.predict(X_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[22747, 46877,    25,     0,     0,     0,     0],\n",
       "       [25611, 67752,    95,     0,     0,     0,     0],\n",
       "       [ 1110,  9765,  1007,     0,     0,     0,     0],\n",
       "       [  134,   747,    36,     0,     0,     0,     0],\n",
       "       [  723,  2449,    40,     0,     0,     0,     0],\n",
       "       [  575,  4911,   282,     0,     0,     0,     0],\n",
       "       [ 2192,  4656,     0,     0,     0,     0,     0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "test_conf_LR_10=confusion_matrix(y_test,Test_y_hat)\n",
    "test_conf_LR_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 8643, 61006,     0,     0,     0,     0,     0],\n",
       "       [ 9634, 83740,    79,     0,     0,     0,     5],\n",
       "       [  513, 11238,   131,     0,     0,     0,     0],\n",
       "       [  136,   781,     0,     0,     0,     0,     0],\n",
       "       [  409,  2803,     0,     0,     0,     0,     0],\n",
       "       [  409,  5317,    42,     0,     0,     0,     0],\n",
       "       [  593,  6255,     0,     0,     0,     0,     0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "test_conf_LR_20=confusion_matrix(y_test,Test_y_hat_20)\n",
    "test_conf_LR_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           1       0.43      0.33      0.37     69649\n           2       0.49      0.72      0.59     93458\n           3       0.68      0.08      0.15     11882\n           4       0.00      0.00      0.00       917\n           5       0.00      0.00      0.00      3212\n           6       0.00      0.00      0.00      5768\n           7       0.00      0.00      0.00      6848\n\n    accuracy                           0.48    191734\n   macro avg       0.23      0.16      0.16    191734\nweighted avg       0.44      0.48      0.43    191734\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, Test_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           1       0.42      0.12      0.19     69649\n           2       0.49      0.90      0.63     93458\n           3       0.52      0.01      0.02     11882\n           4       0.00      0.00      0.00       917\n           5       0.00      0.00      0.00      3212\n           6       0.00      0.00      0.00      5768\n           7       0.00      0.00      0.00      6848\n\n    accuracy                           0.48    191734\n   macro avg       0.20      0.15      0.12    191734\nweighted avg       0.43      0.48      0.38    191734\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,Test_y_hat_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10=X_train_conv[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "X_test_10 = X_test[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "X_train_20=X_train_conv[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]\n",
    "X_test_20 = X_test[['V1',  'V3',  'V5',  'V6', 'V12', 'V14', 'V16', 'V19', 'V20', 'V24', 'V25', 'V26', 'V27', 'V28', 'V30', 'V31', 'V34', 'V43', 'V44', 'V46']]\n",
    "\n",
    "X_train_ori=X_train[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "y_train_ori=y_train\n",
    "X_test_ori = X_test[[ 'V1',  'V3',  'V6', 'V12', 'V14', 'V24', 'V27', 'V28', 'V34', 'V44']]\n",
    "y_test_ori=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA_10_model = QuadraticDiscriminantAnalysis().fit(X_train_10,X_train_conv[['V55']])\n",
    "QDA_20_model = QuadraticDiscriminantAnalysis().fit(X_train_20,X_train_conv[['V55']])\n",
    "LDA_10_model = LinearDiscriminantAnalysis().fit(X_train_10,X_train_conv[['V55']])\n",
    "LDA_20_model = LinearDiscriminantAnalysis().fit(X_train_20,X_train_conv[['V55']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_QDA_10 = QDA_10_model.predict(X_test_10)\n",
    "yhat_QDA_20 = QDA_20_model.predict(X_test_20)\n",
    "yhat_LDA_10 =LDA_10_model.predict(X_test_10)\n",
    "yhat_LDA_20 =LDA_20_model.predict(X_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[    0     0 69649     0     0     0     0]\n",
      " [    0     0 93458     0     0     0     0]\n",
      " [    0     0 11882     0     0     0     0]\n",
      " [    0     0   917     0     0     0     0]\n",
      " [    0     0  3212     0     0     0     0]\n",
      " [    0     0  5768     0     0     0     0]\n",
      " [    0     0  6848     0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     69649\n",
      "           2       0.00      0.00      0.00     93458\n",
      "           3       0.06      1.00      0.12     11882\n",
      "           4       0.00      0.00      0.00       917\n",
      "           5       0.00      0.00      0.00      3212\n",
      "           6       0.00      0.00      0.00      5768\n",
      "           7       0.00      0.00      0.00      6848\n",
      "\n",
      "    accuracy                           0.06    191734\n",
      "   macro avg       0.01      0.14      0.02    191734\n",
      "weighted avg       0.00      0.06      0.01    191734\n",
      "\n",
      "[[    0     0 69649     0     0     0     0]\n",
      " [    0     0 93458     0     0     0     0]\n",
      " [    0     0 11882     0     0     0     0]\n",
      " [    0     0   917     0     0     0     0]\n",
      " [    0     0  3212     0     0     0     0]\n",
      " [    0     0  5768     0     0     0     0]\n",
      " [    0     0  6848     0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00     69649\n",
      "           2       0.00      0.00      0.00     93458\n",
      "           3       0.06      1.00      0.12     11882\n",
      "           4       0.00      0.00      0.00       917\n",
      "           5       0.00      0.00      0.00      3212\n",
      "           6       0.00      0.00      0.00      5768\n",
      "           7       0.00      0.00      0.00      6848\n",
      "\n",
      "    accuracy                           0.06    191734\n",
      "   macro avg       0.01      0.14      0.02    191734\n",
      "weighted avg       0.00      0.06      0.01    191734\n",
      "\n",
      "[[47267 21318     0     0   199    55   810]\n",
      " [19939 69568   456     0  1841  1654     0]\n",
      " [    0  4399  5778    37     0  1668     0]\n",
      " [    0     0   812    50     0    55     0]\n",
      " [    0  2536     0     0   663    13     0]\n",
      " [    0  1537  2056    99     0  2076     0]\n",
      " [ 6387    25     0     0     0     0   436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.68      0.66     69649\n",
      "           2       0.70      0.74      0.72     93458\n",
      "           3       0.63      0.49      0.55     11882\n",
      "           4       0.27      0.05      0.09       917\n",
      "           5       0.25      0.21      0.22      3212\n",
      "           6       0.38      0.36      0.37      5768\n",
      "           7       0.35      0.06      0.11      6848\n",
      "\n",
      "    accuracy                           0.66    191734\n",
      "   macro avg       0.46      0.37      0.39    191734\n",
      "weighted avg       0.64      0.66      0.64    191734\n",
      "\n",
      "[[48010 19138     0     0   344   204  1953]\n",
      " [20406 65313  1037     0  4231  2307   164]\n",
      " [    0  2695  8125    92   384   586     0]\n",
      " [    0     0   682   148     0    87     0]\n",
      " [    2  2151    85     0   708   266     0]\n",
      " [    0   921  3237   106    77  1427     0]\n",
      " [ 5031    26     0     0     0     0  1791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.69      0.67     69649\n",
      "           2       0.72      0.70      0.71     93458\n",
      "           3       0.62      0.68      0.65     11882\n",
      "           4       0.43      0.16      0.23       917\n",
      "           5       0.12      0.22      0.16      3212\n",
      "           6       0.29      0.25      0.27      5768\n",
      "           7       0.46      0.26      0.33      6848\n",
      "\n",
      "    accuracy                           0.65    191734\n",
      "   macro avg       0.47      0.42      0.43    191734\n",
      "weighted avg       0.66      0.65      0.65    191734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,yhat_QDA_10))\n",
    "print(classification_report(y_test,yhat_QDA_10))\n",
    "\n",
    "print(confusion_matrix(y_test,yhat_QDA_20))\n",
    "print(classification_report(y_test,yhat_QDA_20))\n",
    "\n",
    "print(confusion_matrix(y_test,yhat_LDA_10))\n",
    "print(classification_report(y_test,yhat_LDA_10))\n",
    "\n",
    "print(confusion_matrix(y_test,yhat_LDA_20))\n",
    "print(classification_report(y_test,yhat_LDA_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "QDA_10_model = QuadraticDiscriminantAnalysis().fit(X_train_10,X_train_conv[['V55']])\n",
    "QDA_20_model = QuadraticDiscriminantAnalysis().fit(X_train_20,X_train_conv[['V55']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1,7)\n",
    "train_accuracy =np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #Fit the model\n",
    "    knn.fit(X_train_10, X_train_conv[['V55']])\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train_10,  X_train_conv[['V55']])\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(X_test_10, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.        , 0.78002018, 0.77194753, 0.72653885, 0.70837538,\n",
       "       0.7184662 ])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.57142708, 0.58476327, 0.61026213, 0.61848186, 0.63378431,\n",
       "       0.63478048])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[49177 19157    23     0     0     3  1289]\n",
      " [27867 64087  1122     0     0   278   104]\n",
      " [  183  3660  5842   215     0  1982     0]\n",
      " [    0     7   567   132     0   211     0]\n",
      " [  343  2801    58     0     0    10     0]\n",
      " [   50  1922  2377    95     0  1324     0]\n",
      " [ 5520   181     0     0     0     0  1147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.71      0.64     69649\n",
      "           2       0.70      0.69      0.69     93458\n",
      "           3       0.58      0.49      0.53     11882\n",
      "           4       0.30      0.14      0.19       917\n",
      "           5       0.00      0.00      0.00      3212\n",
      "           6       0.35      0.23      0.28      5768\n",
      "           7       0.45      0.17      0.24      6848\n",
      "\n",
      "    accuracy                           0.63    191734\n",
      "   macro avg       0.42      0.35      0.37    191734\n",
      "weighted avg       0.62      0.63      0.62    191734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "    \n",
    "#Fit the model\n",
    "knn.fit(X_train_10, X_train_conv[['V55']])\n",
    "    \n",
    "#Compute accuracy on the training set\n",
    "yhat_knn_10=knn.predict(X_test_10)\n",
    "\n",
    "print(confusion_matrix(y_test,yhat_knn_10))\n",
    "print(classification_report(y_test,yhat_knn_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10)\n",
    "tree_clf.fit(X_train_10, X_train_conv[['V55']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_tree_10=tree_clf.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[43907 22879    29     0   202    42  2590]\n",
      " [25382 64189  1435     2  1410   807   233]\n",
      " [  331  2663  5077   941   364  2506     0]\n",
      " [    0    15   378   456     0    68     0]\n",
      " [  201  2502    86     0   402    21     0]\n",
      " [   62  1319  1798   293   142  2154     0]\n",
      " [ 3972   419     0     0     0     0  2457]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.63      0.61     69649\n",
      "           2       0.68      0.69      0.68     93458\n",
      "           3       0.58      0.43      0.49     11882\n",
      "           4       0.27      0.50      0.35       917\n",
      "           5       0.16      0.13      0.14      3212\n",
      "           6       0.38      0.37      0.38      5768\n",
      "           7       0.47      0.36      0.41      6848\n",
      "\n",
      "    accuracy                           0.62    191734\n",
      "   macro avg       0.45      0.44      0.44    191734\n",
      "weighted avg       0.62      0.62      0.62    191734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,yhat_tree_10))\n",
    "print(classification_report(y_test,yhat_tree_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2. 2. 2. ... 1. 6. 6.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-270-93e344985222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat_tree_10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2. 2. 2. ... 1. 6. 6.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 3, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "#tree\n",
    "yhat_tree_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 3, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "#KNN\n",
    "yhat_knn_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 1, 3, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "#LDA\n",
    "yhat_LDA_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "191734"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "len(yhat_tree_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "191734"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble=[]\n",
    "for i in range(len(y_test)):\n",
    "\n",
    "    a=yhat_LDA_10[i]\n",
    "    if(a==yhat_knn_10[i]):\n",
    "        ensemble.append(a)\n",
    "    else:\n",
    "        if(a==yhat_tree_10[i]):\n",
    "            ensemble.append(a)\n",
    "        elif(yhat_knn_10[i]==yhat_tree_10[i]):\n",
    "            ensemble.append(yhat_tree_10[i])\n",
    "        else:\n",
    "            ensemble.append(a)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[48739 19880     0     0    99    32   899]\n",
      " [22382 68877   635     0   662   845    57]\n",
      " [   71  3925  6220    82     0  1584     0]\n",
      " [    0     2   735   139     0    41     0]\n",
      " [   39  2872    45     0   252     4     0]\n",
      " [    0  1700  2183    61     0  1824     0]\n",
      " [ 5979    38     0     0     0     0   831]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.70      0.66     69649\n",
      "           2       0.71      0.74      0.72     93458\n",
      "           3       0.63      0.52      0.57     11882\n",
      "           4       0.49      0.15      0.23       917\n",
      "           5       0.25      0.08      0.12      3212\n",
      "           6       0.42      0.32      0.36      5768\n",
      "           7       0.47      0.12      0.19      6848\n",
      "\n",
      "    accuracy                           0.66    191734\n",
      "   macro avg       0.51      0.38      0.41    191734\n",
      "weighted avg       0.65      0.66      0.65    191734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,ensemble))\n",
    "print(classification_report(y_test,ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}